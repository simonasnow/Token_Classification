{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a372211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "DIR= r'/Token_Classification/'\n",
    "js_path = os.path.join(DIR, 'ner_dataset.json')\n",
    "js_file = open(js_path)\n",
    "\n",
    "js_dict = json.load(js_file)\n",
    "# for k,v in js_dict.items():\n",
    "  #   print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8944259c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "21\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(js_dict['train']))\n",
    "print(len(js_dict['valid']))\n",
    "print(len(js_dict['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a213860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_data(key):\n",
    "    sentences = []\n",
    "    labels_sentence = []\n",
    "\n",
    "    for doc in key:\n",
    "        for sent in doc:\n",
    "            tokens = [t[0] for t in sent]\n",
    "            sentences.append(tokens)\n",
    "            labels = [t[1] for t in sent]\n",
    "            labels_sentence.append(labels)    \n",
    "\n",
    "    return sentences, labels_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e4f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_train, labels_sent_train= unzip_data(js_dict['train'])\n",
    "sent_val, labels_sent_val = unzip_data(js_dict['valid'])\n",
    "sent_test, labels_sent_test= unzip_data(js_dict['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6d294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 2)\n",
      "(177, 2)\n",
      "(315, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.DataFrame(zip(sent_train, labels_sent_train), columns=['sentence', 'label_sentence'])\n",
    "df_val = pd.DataFrame(zip(sent_val, labels_sent_val), columns=['sentence', 'label_sentence'])\n",
    "df_test = pd.DataFrame(zip(sent_test, labels_sent_test), columns=['sentence', 'label_sentence'])\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8573d0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1332, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join 'train'and 'valid' data to make bigger the training set\n",
    "df_train_ = pd.concat([df_train, df_val])\n",
    "df_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b2c7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels in ids\n",
    "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "\n",
    "label2id = {v: k for k, v in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4734261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(df, label_list):\n",
    "    df['ids_labels'] = df['label_sentence'].transform(lambda x: [int(label2id[i]) for i in x])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4c890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = convert_labels(df_train_, label_list)\n",
    "df_test1 = convert_labels(df_test, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d426261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = df_train1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172e99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dt_train = Dataset.from_pandas(df_train1)\n",
    "dt_test = Dataset.from_pandas(df_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "204ca465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label_sentence', 'ids_labels'],\n",
       "        num_rows: 1332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label_sentence', 'ids_labels'],\n",
       "        num_rows: 315\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "dataset = DatasetDict({'train': dt_train, 'test':dt_test})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90aa54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set name BERT-model, batch size, learning rate\n",
    "model_checkpoint = \"distilbert-base-uncased\" #uncased works better\n",
    "batch_size = 8\n",
    "lr = 2e-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "686714f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.is_fast #check tokenizer is backed by Tokenizers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "933cc236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize sentences, align labels ids to tokenized sentences adding -100 \n",
    "# as a special token (ignored by cross entropy loss function), \n",
    "# and coping with multiple tokens for a same word\n",
    "\n",
    "def tokenize_(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"sentence\"], truncation=True, is_split_into_words=True)  \n",
    "    \n",
    "    labels=[]\n",
    "\n",
    "    for i, label in enumerate(examples['ids_labels']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        new_labels = []\n",
    "        current_word = None\n",
    "\n",
    "        for word_id in word_ids:\n",
    "\n",
    "            if word_id != current_word: #new word\n",
    "                current_word = word_id\n",
    "                l = -100 if word_id is None else label[word_id]\n",
    "                new_labels.append(l)\n",
    "            \n",
    "            elif word_id is None: #special token\n",
    "                l = -100\n",
    "                new_labels.append(l)\n",
    "\n",
    "            else: #same word \n",
    "                l = label[word_id]\n",
    "                new_labels.append(l)\n",
    "\n",
    "        labels.append(new_labels)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "477f48e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 4533, 1011, 15659, 4152, 2248, 2655, 2039, 1012, 102], [101, 15976, 2727, 1011, 5511, 1011, 2654, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 1, 0, 0, 0, 0, 0, -100], [-100, 5, 0, 0, 0, 0, 0, -100]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"train\"][:2]\n",
    "t_example = tokenize_(example)\n",
    "t_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c069af0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244941c7614a4a4faf2f04355a8478cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3f78d29a094370afd3c814297a856e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels'],\n",
       "        num_rows: 1332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels'],\n",
       "        num_rows: 315\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e323602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find max lengh of sentences for padding\n",
    "def FindMaxLength(lst):\n",
    "    max_length = max(len(x) for x in lst )\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93f12795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "list_of_list = []\n",
    "\n",
    "for i in tokenized_dataset['train']:\n",
    "    list_of_list.append(i['input_ids'])\n",
    "print(len(list_of_list))\n",
    "max_length = FindMaxLength(list_of_list)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5df51a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer,\n",
    "                                                   padding='max_length', \n",
    "                                                   max_length=max_length)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"test\"], \n",
    "    collate_fn=data_collator, \n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a076a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set low number of epochs to prevent overfitting\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6e603c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_f1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   precision  recall   f1  number\n",
       "LOC                      1.0     1.0  1.0       1\n",
       "MISC                     1.0     1.0  1.0       1\n",
       "PER                      1.0     1.0  1.0       2\n",
       "overall_precision        1.0     1.0  1.0       1\n",
       "overall_recall           1.0     1.0  1.0       1\n",
       "overall_f1               1.0     1.0  1.0       1\n",
       "overall_accuracy         1.0     1.0  1.0       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"seqeval\") #CoNLL\n",
    "\n",
    "example = dataset[\"train\"][4]\n",
    "labels = [label_list[i] for i in example['ids_labels']]\n",
    "results = metric.compute(predictions=[labels], references=[labels])\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results_ = df_results.T\n",
    "df_results_.number = df_results_.number.astype(int)\n",
    "display(df_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "893789f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process predictions and true labels for metric \n",
    "# avoiding -100 token and converting ids in labels\n",
    "\n",
    "def postprocess(predictions, labels, label_list):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    true_labels = [\n",
    "        [label_list[l] for l in label if l != -100] for label in labels]\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)]\n",
    "    \n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31855b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import net\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "from classes import Model_TC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b067dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss\n",
    "def loss_funct(labels, mask_ids, logits, num_labels):\n",
    "    loss = None\n",
    "    if labels is not None:\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        if mask_ids is not None:\n",
    "            active_loss = mask_ids.view(-1) == 1\n",
    "            active_logits = logits.view(-1, num_labels)\n",
    "            active_labels = torch.where(\n",
    "                active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
    "                    )\n",
    "            loss = loss_fct(active_logits, active_labels)\n",
    "        else:\n",
    "            loss = loss_fct(logits.view(-1, num_labels), labels.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38896941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f38db9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bd85fdbda94619ae4c2b0d020fc2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=501.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Training epoch took: 0:05:05\n",
      "  train_loss: 0.55337 valid_loss: 0.30363\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.395437</td>\n",
       "      <td>0.513580</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.876494</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.625360</td>\n",
       "      <td>0.630814</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision    recall        f1  number\n",
       "LOC    0.732394  0.395437  0.513580     263\n",
       "PER    0.887097  0.866142  0.876494     127\n",
       "MISC   0.166667  0.578947  0.258824      19\n",
       "ORG    0.636364  0.625360  0.630814     347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_precision:  0.6568\n",
      "overall_recall:  0.5847\n",
      "overall_f1:  0.6186\n",
      "\n",
      "saving...\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Training epoch took: 0:05:21\n",
      "  train_loss: 0.36677 valid_loss: 0.25931\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.697183</td>\n",
       "      <td>0.502538</td>\n",
       "      <td>0.584071</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.703812</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.699708</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision    recall        f1  number\n",
       "LOC    0.697183  0.502538  0.584071     197\n",
       "PER    0.854839  0.913793  0.883333     116\n",
       "MISC   0.409091  0.428571  0.418605      63\n",
       "ORG    0.703812  0.695652  0.699708     345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_precision:  0.7013\n",
      "overall_recall:  0.6546\n",
      "overall_f1:  0.6772\n",
      "\n",
      "saving...\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Training epoch took: 0:05:14\n",
      "  train_loss: 0.28419 valid_loss: 0.23761\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.879032</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.882591</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.718475</td>\n",
       "      <td>0.704023</td>\n",
       "      <td>0.711176</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision    recall        f1  number\n",
       "LOC    0.704225  0.526316  0.602410     190\n",
       "PER    0.879032  0.886179  0.882591     123\n",
       "MISC   0.409091  0.337500  0.369863      80\n",
       "ORG    0.718475  0.704023  0.711176     348"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_precision:  0.7147\n",
      "overall_recall:  0.6491\n",
      "overall_f1:  0.6803\n",
      "\n",
      "saving...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from accelerate import Accelerator\n",
    "\n",
    "torch.manual_seed(42) #for reproducibility\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "num_labels=len(label_list)\n",
    "classifier = Model_TC.TokenClassifier(model_checkpoint, num_labels=num_labels, freeze_bert=False)\n",
    "\n",
    "output_file= os.path.join(DIR, 'model_classifier.pth')\n",
    "\n",
    "optimizer = AdamW(classifier.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "# handle the device placement for training\n",
    "accelerator = Accelerator()\n",
    "classifier, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(classifier, optimizer, train_dataloader, eval_dataloader)\n",
    "\n",
    "# tracking the training loss\n",
    "train_losses = []\n",
    "# tracking the validation loss\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Training\n",
    "    classifier.train()\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        labels = batch[\"labels\"]\n",
    "        input_ids = batch['input_ids']\n",
    "        mask_ids = batch['attention_mask']\n",
    "\n",
    "        logits = classifier(input_ids, mask_ids)\n",
    "        \n",
    "        loss = loss_funct(labels, mask_ids, logits, num_labels)\n",
    "        \n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    avg_train_loss = np.average(train_losses)\n",
    "    \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # Evaluation\n",
    "    classifier.eval()\n",
    "    \n",
    "    for batch in eval_dataloader:\n",
    "        labels = batch[\"labels\"]\n",
    "        input_ids = batch['input_ids']\n",
    "        mask_ids = batch['attention_mask']\n",
    "  \n",
    "        with torch.no_grad():\n",
    "            outputs = classifier(input_ids, mask_ids)\n",
    "        \n",
    "        loss = loss_funct(labels, mask_ids, outputs, num_labels)\n",
    "        valid_losses.append(loss.item())\n",
    "\n",
    "        predictions = outputs.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # padding predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered, label_list)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    avg_valid_loss = np.average(valid_losses)\n",
    "            \n",
    "    print_msg = (f'  train_loss: {avg_train_loss:.5f} ' + \n",
    "                 f'valid_loss: {avg_valid_loss:.5f}')\n",
    "    print(print_msg)\n",
    "\n",
    "    print(\"\")\n",
    "    results = metric.compute()\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results_ = df_results[['LOC', 'PER', 'MISC', 'ORG']]\n",
    "    df_results_ = df_results_.T\n",
    "    df_results_.number = df_results_.number.astype(int)\n",
    "    display(df_results_)\n",
    "    print('overall_precision: ', round(df_results['overall_precision'][0], 4))\n",
    "    print('overall_recall: ', round(df_results['overall_recall'][0], 4))\n",
    "    print('overall_f1: ', round(df_results['overall_f1'][0], 4))\n",
    "    print(\"\")\n",
    "    \n",
    "    print('saving...')\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(classifier)\n",
    "    accelerator.save({        \n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': unwrapped_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss}, output_file)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f6336c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
